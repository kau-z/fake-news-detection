{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4517f94-df21-44c2-814c-6561dd7bc76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "true = pd.read_csv(\"../data/raw/True.csv\")\n",
    "fake = pd.read_csv(\"../data/raw/Fake.csv\")\n",
    "\n",
    "true['label'] = 0   # real\n",
    "fake['label'] = 1   # fake\n",
    "\n",
    "df = pd.concat([true, fake], ignore_index=True).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e44f35b-4417-4c30-8edd-3ef39aae9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['title'].fillna('') + \" \" + df['text'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e726f730-f8cc-4826-8d53-c0bd981fe8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b91e55-eef4-486b-9229-c4456beae491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \" \", text)  # remove urls\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)        # keep only letters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)             # remove extra spaces\n",
    "    return text.strip()\n",
    "\n",
    "df['content'] = df['content'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b1d9f5e-1dc7-4b43-9bb4-8b6bc0290a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kausalya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join([w for w in x.split() if w not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad740e7-cdbf-4c38-8d49-b231e6457ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kausalya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['content'] = df['content'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f69c59-a9f2-4a22-96f4-76fa6d60c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['content'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "454a8987-a89d-464c-bed8-9baa6552602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (35918,)\n",
      "Test size: (8980,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['content']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fec0a92-a660-42fe-81b3-9620f2d4843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "df.to_csv(\"../data/processed/cleaned_fake_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242d36e4-c72a-436e-a790-52011fb31ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
